{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04f610a",
   "metadata": {},
   "source": [
    "For producing the figures you will need the conda environment:\n",
    "\n",
    "conda env create -f eval.yml\n",
    "\n",
    "And you will need to first run:\n",
    "\n",
    "python evaluation_scenarios.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f253b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "import matplotlib.pyplot as plt\n",
    "from upsetplot import UpSet\n",
    "from matplotlib_venn import venn3, venn2\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from scipy.stats import wilcoxon\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import os\n",
    "from pyfaidx import Fasta\n",
    "import re\n",
    "main_dir = \".\" # TODO set working directory\n",
    "data_dir = f\"{main_dir}/data\"\n",
    "pred_dir = f'{data_dir}/predictions'\n",
    "out_dir = f\"{main_dir}/out\"\n",
    "stats_dir = f\"{out_dir}/stats\"\n",
    "include_ag_results = True\n",
    "stats_dir_ag = f\"{out_dir}/stats_alphagenome\"\n",
    "plt_dir = f\"{out_dir}/plots\"\n",
    "os.makedirs(plt_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Distribution of JCC prediction scores for Scenario 3 “Predicting hard-to-find junctions” in Real-world use case\n",
    "in_dir = f'{stats_dir}/scenario_3_real_world'\n",
    "aligner=\"star\"\n",
    "tool = \"jcc\"\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 3.5))  # 3 horizontal subplots\n",
    "for i, gt_confidence in enumerate([\"unfiltered\",\"illumina\",\"cutoff\"]):\n",
    "\tfile_sj_50 = f'{in_dir}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\tgt_confidence = gt_confidence.capitalize() if gt_confidence == 'illumina' else gt_confidence\n",
    "\twith open(file_sj_50, 'rb') as f:\n",
    "\t\tsjs_50 = pd.read_pickle(f)\n",
    "\t\tfor ann, sj in sjs_50[tool].items():\n",
    "\t\t\t_, sample_id, run_id = ann\n",
    "\t\t\tif sample_id == 'J26675-L1_S1' and run_id == '0':\n",
    "\t\t\t\t\tax = axs[i]\n",
    "\t\t\t\t\tbins = np.histogram_bin_edges(sj['pred'], bins=25)\n",
    "\t\t\t\t\tax.hist(sj[sj['label'] == 0]['pred'], bins=bins, alpha=0.6, label='Negative (label=0)')\n",
    "\t\t\t\t\tax.hist(sj[sj['label'] == 1]['pred'], bins=bins, alpha=0.6, label='Positive (label=1)')\n",
    "\t\t\t\t\tax.set_xlabel(f'{tool.upper()} prediction score', fontsize=14)\n",
    "\t\t\t\t\tax.set_ylabel('Number of junctions', fontsize=14)\n",
    "\t\t\t\t\tax.set_yscale('log')\n",
    "\t\t\t\t\tax.tick_params(labelsize=14)\n",
    "\t\t\t\t\tax.set_xlim(-0.02, 1.02)\n",
    "\t\t\t\t\tif i == 2:\n",
    "\t\t\t\t\t\tax.legend(fontsize=14)\n",
    "\t\t\t\t\tax.grid(True)\n",
    "\t\t\t\t\tax.title.set_text(f'{aligner.upper()} {gt_confidence}')\n",
    "\t\t\t\t\tax.title.set_fontsize(16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plt_dir}/figure_2s.tif', dpi=600, transparent=True, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S1: plot upsetplot of all groundtruths \n",
    "\n",
    "labels = [\"GRCh38.106 reference genome\"]\n",
    "reference_sj = pd.read_csv(f\"{data_dir}/annotated.sj\",sep='\\t', header=None, names=[\"chr\", \"start\", \"end\", \"strand\"], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int})\n",
    "# keep only chr1-22, X, Y\n",
    "reference_sj = reference_sj[reference_sj[\"chr\"].isin([str(i) for i in range(1,23)] + [\"X\",\"Y\"])]\n",
    "reference_sj = reference_sj.drop_duplicates()\n",
    "\n",
    "sets = [reference_sj]\n",
    "\n",
    "for aligner in [\"hisat\",\"star\"]:\n",
    "\tfor filter_type in ([\"unfiltered\",\"illumina\",\"cutoff\"] if aligner == \"star\" else [\"unfiltered\"]):\n",
    "\t\tsample_sets = []\n",
    "\t\tfor sample in [\"J26675-L1_S1\",\"J26676-L1_S2\",\"J26677-L1_S3\",\"J26678-L1_S4\"]:\n",
    "\t\t\tsample_sets.append(pd.read_csv(f\"{data_dir}/500M/{sample}_{aligner}_{filter_type}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"]))\n",
    "\t\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type\n",
    "\t\tfilter_type_ = filter_type_ if filter_type_ == \"unfiltered\" else filter_type_+\" filtered\"\n",
    "\t\taligner_ = aligner.upper()+'2' if aligner == \"hisat\" else aligner.upper()\n",
    "\t\tlabels.append(aligner_+\" \"+filter_type_+\" gold standard\")\n",
    "\t\tcombined_sj = pd.concat(sample_sets, ignore_index=True).drop_duplicates()\n",
    "\t\tsets.append(combined_sj)\n",
    "\n",
    "# Merge all dataframes with an additional 'source' column\n",
    "merged_df = pd.concat(\n",
    "\t[df.assign(source=name) for name, df in zip(labels, sets)],\n",
    "\tignore_index=True\n",
    ")\n",
    "\n",
    "# get counts for each group\n",
    "binary_merged = merged_df.pivot_table(index=['chr','start','end','strand'], columns='source', aggfunc='size', fill_value=0).clip(upper=1)\n",
    "g = binary_merged.groupby(binary_merged.columns.tolist()).size()\n",
    "g = g.reorder_levels(labels)\n",
    "\n",
    "upset = UpSet(g, show_counts=True, sort_categories_by='-input', sort_by='-degree')\n",
    "upset.plot()\n",
    "plt.subplots_adjust(right=1.25)\n",
    "plt.savefig(f'{plt_dir}/supplementary_figure_1.tif', dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6712d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot venn diagram for three sets a,b,c\n",
    "def prep_for_venn3(a, b, c, colored = True):\n",
    "\tthree_sets = {}\n",
    "\ta_c = a.merge(c, how='inner', on=['chr','start','end','strand'])\n",
    "\ta_b_c = a_c.merge(b, how='outer', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['101'] = len(a_b_c[a_b_c._merge=='left_only'])\n",
    "\tthree_sets['111'] = len(a_b_c[a_b_c._merge=='both'])\n",
    "\tb_c = b.merge(c, how='inner', on=['chr','start','end','strand'])\n",
    "\ta_b_c = b_c.merge(a, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['011'] = len(a_b_c[a_b_c._merge=='left_only'])\n",
    "\ta_b = a.merge(b, how='inner', on=['chr','start','end','strand'])\n",
    "\ta_b_c = a_b.merge(c, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['110'] = len(a_b_c[a_b_c._merge=='left_only'])\n",
    "\ta_nb = a.merge(b, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\ta_nb_nc = a_nb[a_nb._merge=='left_only'].drop(columns=['_merge']).merge(c, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['100'] = len(a_nb_nc[a_nb_nc._merge=='left_only'])\n",
    "\tna_b = a.merge(b, how='right', on=['chr','start','end','strand'], indicator=True)\n",
    "\tna_b_nc = na_b[na_b._merge=='right_only'].drop(columns=['_merge']).merge(c, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['010'] = len(na_b_nc[na_b_nc._merge=='left_only'])\n",
    "\tna_c = a.merge(c, how='right', on=['chr','start','end','strand'], indicator=True)\n",
    "\tna_nb_c = na_c[na_c._merge=='right_only'].drop(columns=['_merge']).merge(b, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['001'] = len(na_nb_c[na_nb_c._merge=='left_only'])\n",
    "\ttab10 = plt.cm.tab10.colors \n",
    "\tcolors = [tab10[0], tab10[1], tab10[2]] if colored else [tab10[0], tab10[0], tab10[0]]\n",
    "\treturn three_sets, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S2\n",
    "# plot overlap STAR 500M with different filtering in VENN diagrams with 3 sets as example sample_id J26675-L1_S1\n",
    "sample = 'J26675-L1_S1'\n",
    "aligner = 'star'\n",
    "sjs = {}\n",
    "for filter_type in [\"unfiltered\",\"illumina\",\"cutoff\"]:\n",
    "\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type\n",
    "\tsjs[f'{aligner.upper()} {filter_type_}'] = pd.read_csv(f\"{data_dir}/500M/{sample}_{aligner}_{filter_type}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "three_sets, colors = prep_for_venn3(*sjs.values(), colored=False)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "venn3(subsets=three_sets, set_labels = sjs.keys(), set_colors=colors, ax=ax)\n",
    "plt.savefig(f'{plt_dir}/supplementary_figure_2.tif', dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S3\t\t\n",
    "# plot overlap 50M with 500M with reference genome gtf in Venn diagrams with 3 sets as example subsample 0 of sample_id J26675-L1_S1\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "for ax, aligner in zip(axes,[\"star\",\"hisat\"]):\n",
    "\tsample = 'J26675-L1_S1'\n",
    "\ti=0\n",
    "\tfilter_type = 'unfiltered'\n",
    "\ttitle =''\n",
    "\tfull = pd.read_csv(f\"{data_dir}/500M/{sample}_{aligner}_{filter_type}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "\tsubsampled = pd.read_csv(f\"{data_dir}/50M/{aligner}/{sample}_50M_{i}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "\treference_sj = pd.read_csv(f\"{data_dir}/annotated.sj\",sep='\\t', header=None, names=[\"chr\", \"start\", \"end\", \"strand\"], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int})\n",
    "\taligner_ = aligner.upper()+'2' if aligner == \"hisat\" else aligner.upper()\n",
    "\tthree_sets, colors = prep_for_venn3(full, subsampled, reference_sj)\n",
    "\tvenn = venn3(subsets=three_sets, set_labels = [f'{aligner_} 500M', f'{aligner_} 50M', 'reference genome'], set_colors=colors, ax=ax)\n",
    "\t# make set labels colored\n",
    "\tfor i, text in enumerate(venn.set_labels):\n",
    "\t\ttext.set_color(plt.cm.tab10.colors [i])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plt_dir}/supplementary_figure_3.tif', dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd081324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S4: Precision-Recall curves of the tools over the different evaluation scenarios for STAR unfiltered, STAR Illumina filtered, STAR cutoff filtered and HISAT unfiltered gold standards.\n",
    "TOOL_COLORS = {'deepsplice':0, 'spliceai':1, 'jcc':2, 'baseline':3, 'alphagenome':4}\n",
    "tool2tool = {'alphagenome':'AlphaGenome','spliceai':'SpliceAI','deepsplice':'DeepSplice','jcc':'JCC'}\n",
    "fig, axes = plt.subplots(5, 4, figsize=(4*4.5, 5*4), squeeze=False)\n",
    "for row_idx, scenario in enumerate(['scenario_1a','scenario_1b','scenario_2_hypothetical','scenario_2_real_world','scenario_3_hypothetical']): \n",
    "\tfor col_idx, (aligner, gt_confidence) in enumerate([('star','unfiltered'),('star','illumina'),('star','cutoff'),('hisat','unfiltered')]):\n",
    "\t\tax = axes[row_idx][col_idx]\n",
    "\t\tif (('real_world' in scenario) and (aligner == 'hisat')):\n",
    "\t\t\tax.axis('off')\n",
    "\t\telse:\n",
    "\t\t\tsj_file = f'{stats_dir}/{scenario}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\t\t\tsj_file_ag = f'{stats_dir_ag}/{scenario}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\t\t\tif (scenario == 'scenario_3_hypothetical') and include_ag_results and os.path.exists(sj_file_ag):\n",
    "\t\t\t\tsj_file = sj_file_ag\n",
    "\t\t\twith open(sj_file,'rb') as f:\n",
    "\t\t\t\ttool_sjs_50 = pickle.load(f)\n",
    "\t\t\tfor tool, sjs in tool_sjs_50.items():\n",
    "\t\t\t\ty_true = np.concatenate([sj[\"label\"] for sj in sjs.values()])\n",
    "\t\t\t\ty_scores = np.concatenate([sj[\"pred\"] for sj in sjs.values()])\n",
    "\t\t\t\tprecision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\t\t\t\tax.plot(recall, precision, label=tool2tool[tool], color=plt.get_cmap('tab10')(TOOL_COLORS[tool]))\n",
    "\t\t\tif row_idx == 0:\n",
    "\t\t\t\tax.set_title(f\"{aligner.upper()}{'2' if aligner=='hisat' else ''} {gt_confidence}\",fontweight='bold', fontsize=12)\n",
    "\t\t\tax.set_xlabel('Recall')\n",
    "\t\t\tax.set_ylim(0, 1.05)\n",
    "\t\t\tax.set_ylabel('Precision')s\n",
    "\t\t\tif col_idx == 0:\n",
    "\t\t\t\tscenario_name = scenario.capitalize().replace('_', ' ')\n",
    "\t\t\t\tax.text(-0.25, 0.5, scenario_name,transform=ax.transAxes,fontsize=12,fontweight='bold',va='center',rotation=90)\n",
    "\t\t\tax.legend()\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_4.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S5: Boxplots of the distribution of the tools' AUPRC scores over the different evaluation scenarios with Wilcoxon test.\n",
    "# Color mapping as specified\n",
    "TOOL_COLORS = {'deepsplice':0, 'spliceai':1, 'jcc':2, 'baseline':3, 'alphagenome':4}\n",
    "\n",
    "# Display name mapping for plotting\n",
    "TOOL_PLOT_NAME = {\n",
    "\t'alphagenome': 'AlphaGenome',\n",
    "\t'spliceai': 'SpliceAI',\n",
    "\t'deepsplice': 'DeepSplice',\n",
    "\t'jcc': 'JCC',\n",
    "\t'baseline': 'No-Skill'\n",
    "}\n",
    "gridspec_kw = {'height_ratios': [1, 1, 1, 1, 1.2]} if include_ag_results else {'height_ratios': [1, 1, 1, 1, 1]}\n",
    "nr_cols = 4\n",
    "nr_rows = 5\n",
    "fig, axes = plt.subplots(nr_rows, nr_cols, figsize=(4*nr_cols, nr_rows*3.5), squeeze=False, gridspec_kw=gridspec_kw)\n",
    "tab10 = plt.get_cmap('tab10')\n",
    "# for hypothetial scenarios only 4 samples and wilcoxon less meaningful\n",
    "for row_idx, scenario in enumerate(['scenario_1a','scenario_1b','scenario_2_hypothetical','scenario_2_real_world','scenario_3_hypothetical']): \n",
    "\tfor col_idx, (aligner, gt_confidence) in enumerate([('star','unfiltered'),('star','illumina'),('star','cutoff'),('hisat','unfiltered')]):\n",
    "\t\tax = axes[row_idx][col_idx]\n",
    "\t\tif (('real_world' in scenario) and (aligner == 'hisat')):\n",
    "\t\t\tax.axis('off')\n",
    "\t\telse:\n",
    "\t\t\tsj_file = f'{stats_dir}/{scenario}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\t\t\tsj_file_ag = f'{stats_dir_ag}/{scenario}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\t\t\tif (scenario == 'scenario_3_hypothetical') and include_ag_results and os.path.exists(sj_file_ag):\n",
    "\t\t\t\tsj_file = sj_file_ag\n",
    "\t\t\twith open(sj_file,'rb') as f:\n",
    "\t\t\t\ttool_sjs = pickle.load(f)\n",
    "\n",
    "\t\t\ttool_names = [key for key in TOOL_PLOT_NAME if key in tool_sjs]\n",
    "\t\t\tplot_names = [TOOL_PLOT_NAME[n] for n in tool_names]\n",
    "\t\t\tn_tools = len(tool_names)\n",
    "\t\t\tall_auprcs = []\n",
    "\t\t\t# Get AUPRCs for all tools\n",
    "\t\t\tfor tool in tool_names:\n",
    "\t\t\t\tsjs = tool_sjs[tool]\n",
    "\t\t\t\tauprcs = []\n",
    "\t\t\t\tfor (_, sample, idx), s in sjs.items():\n",
    "\t\t\t\t\tauprcs.append(average_precision_score(s['label'], s['pred']))\n",
    "\t\t\t\tall_auprcs.append(np.array(auprcs))\n",
    "\t\t\t# Baseline column\n",
    "\t\t\tbaseline_auprcs = []\n",
    "\t\t\tfirst_sjs = next(iter(tool_sjs.values()))\n",
    "\t\t\tfor (_, sample, idx), s in first_sjs.items():\n",
    "\t\t\t\tbaseline_auprcs.append(average_precision_score(\n",
    "\t\t\t\t\ts['label'],\n",
    "\t\t\t\t\tpd.Series([1] * len(s['pred']), index=s['pred'].index)\n",
    "\t\t\t\t))\n",
    "\t\t\tall_auprcs.append(np.array(baseline_auprcs))\n",
    "\t\t\tplot_names.append(TOOL_PLOT_NAME['baseline'])\n",
    "\n",
    "\t\t\t# Boxplot\n",
    "\t\t\tif row_idx == 0:\n",
    "\t\t\t\tax.set_title(f\"{aligner.upper()}{'2' if aligner=='hisat' else ''} {gt_confidence}\", fontweight='bold', fontsize=12)\n",
    "\t\t\tax.set_ylim(0, 1.199)\n",
    "\t\t\tif row_idx == nr_rows-1 and include_ag_results:\n",
    "\t\t\t\tax.set_ylim(0, 1.35)\n",
    "\t\t\tbp = ax.boxplot(all_auprcs, \n",
    "\t\t\t\t\t\t\ttick_labels=plot_names, \n",
    "\t\t\t\t\t\t\tpatch_artist=True)\n",
    "\t\t\tfor i, (box, median) in enumerate(zip(bp['boxes'], bp['medians'])):\n",
    "\t\t\t\ttoolname = tool_names[i] if i<n_tools else 'baseline'\n",
    "\t\t\t\tcolor = tab10(TOOL_COLORS[toolname])\n",
    "\t\t\t\tbox.set_facecolor((color[0], color[1], color[2], 0.25))\n",
    "\t\t\t\tmedian.set_color(color[:3])\n",
    "\n",
    "\t\t\t# Find the max value for annotation placement\n",
    "\t\t\tmax_auprc = max([np.max(au) for au in all_auprcs])\n",
    "\n",
    "\t\t\t# Draw significance for all pairs of tools (excluding baseline vs baseline)\n",
    "\t\t\tbracket_gaps = 0.05 #max(0.005, 0.05 * max_auprc)\n",
    "\t\t\theights = []\n",
    "\t\t\t# Compare each tool to baseline\n",
    "\t\t\tfor i in range(n_tools):\n",
    "\t\t\t\tx1, x2 = i+1, len(all_auprcs) # 1-indexed for plot\n",
    "\t\t\t\ty = max_auprc + bracket_gaps * (len(heights)+1)\n",
    "\t\t\t\theights.append(y)\n",
    "\t\t\t\tif len(all_auprcs[-1]) == len(all_auprcs[i]):\n",
    "\t\t\t\t\tstat, p_value = wilcoxon(all_auprcs[-1], all_auprcs[i], alternative='two-sided')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstat, p_value = wilcoxon(all_auprcs[-1][:1], all_auprcs[i], alternative='two-sided')\n",
    "\t\t\t\t\tif len(all_auprcs[-1][:1]) != len(all_auprcs[i]): print(f'Error: Number of samples is not the same between {tool_names[i]} and baseline.')\n",
    "\n",
    "\t\t\t\tsignificant = \"N.S.\" if ((p_value > 0.05) or np.isnan(p_value)) else (\"*\" if p_value > 0.01 else (\"**\" if p_value > 0.001 else \"***\"))\n",
    "\t\t\t\tax.plot([x1, x2], [y, y], lw=1, c='k')\n",
    "\t\t\t\tax.text((x1 + x2) * 0.5, y, f'{significant} (p='+(f'{p_value:.2e})' if p_value < 0.01 else f'{p_value:.2f})'), ha='center', va='bottom', color='k', fontsize=8)\n",
    "\n",
    "\t\t\t# Compare all pairs of tools excluding baseline\n",
    "\t\t\ttool_indices = range(n_tools)\n",
    "\t\t\tfor idx, (i, j) in enumerate(combinations(tool_indices, 2)):\n",
    "\t\t\t\tx1, x2 = i+1, j+1\n",
    "\t\t\t\ty = max_auprc + bracket_gaps * (len(heights)+1)\n",
    "\t\t\t\theights.append(y)\n",
    "\t\t\t\tif len(all_auprcs[j]) == len(all_auprcs[i]):\n",
    "\t\t\t\t\tstat, p_value = wilcoxon(all_auprcs[j], all_auprcs[i], alternative='two-sided')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstat, p_value = wilcoxon(all_auprcs[j][:1], all_auprcs[i], alternative='two-sided')\n",
    "\t\t\t\t\tif len(all_auprcs[j][:1]) != len(all_auprcs[i]): print(f'Error: Number of samples is not the same between the two compared tools {tool_names[i]} and {tool_names[j]}.')\n",
    "\t\t\t\tsignificant = \"N.S.\" if ((p_value > 0.05) or np.isnan(p_value)) else (\"*\" if p_value > 0.01 else (\"**\" if p_value > 0.001 else \"***\"))\n",
    "\t\t\t\tax.plot([x1, x2], [y, y], lw=1, c='k')\n",
    "\t\t\t\tax.text((x1 + x2) * 0.5, y, f'{significant} (p='+(f'{p_value:.2e})' if p_value < 0.01 else f'{p_value:.2f})'), ha='center', va='bottom', color='k', fontsize=8)\n",
    "\t\t\tax.set_ylabel(\"AUPRC\")\n",
    "\t\t\tif col_idx == 0:\n",
    "\t\t\t\tscenario_name = scenario.capitalize().replace('_', ' ')\n",
    "\t\t\t\tax.text(-0.25, 0.5, scenario_name,transform=ax.transAxes,fontsize=12,fontweight='bold',va='center',rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plt_dir}/supplementary_figure_5.tif', dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S6\n",
    "# JCC scenario_2_real_world positives plot distribution score in 50m data vs not in 50m data\n",
    "tab10 = plt.cm.tab10.colors \n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))  # 3 horizontal subplots\n",
    "for i, gt_confidence in enumerate([\"unfiltered\",\"illumina\",\"cutoff\"]):\n",
    "\tax = axes[i]\n",
    "\taligner =\"star\"\n",
    "\tfile_sj_50 = f'{stats_dir}/scenario_2_real_world/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\twith open(file_sj_50, 'rb') as f:\n",
    "\t\ttool_sjs_50 = pd.read_pickle(f)\n",
    "\ttool = 'jcc'\n",
    "\tfor ann_50, sj_50 in tool_sjs_50[tool].items():\n",
    "\t\t_, sample_id, run_id = ann_50\n",
    "\t\trun_id = int(run_id)\n",
    "\t\tif run_id == 0 and sample_id == \"J26675-L1_S1\":\n",
    "\t\t\tpositives = sj_50[sj_50.label == 1] # positives\n",
    "\t\t\t# read in sj in 50M input\n",
    "\t\t\tinput_data = pd.read_csv(f\"{data_dir}/50M/{aligner}/{sample_id}_50M_{run_id}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "\t\t\t# add column in_input 1 or 0\n",
    "\t\t\tpositives = positives.merge(input_data, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\tpositives['_merge'] = positives['_merge'].astype('object').replace({'both': 1, 'left_only': 0, 'right_only': 0}).astype(int)\n",
    "\t\t\tpositives.rename(columns={'_merge': 'in_input'},inplace=True, errors='raise')\n",
    "\t\t\t# plot distribution of jcc score of sj that are in groundtruth - that are in in 50m data vs not in 50m data\n",
    "\t\t\tax.hist(positives[positives.in_input == 1]['pred'], bins=50, label='in 50M input data', alpha=0.5, color=tab10[1])\n",
    "\t\t\tax.hist(positives[positives.in_input == 0]['pred'], bins=50, label='not in 50M input data', alpha=0.5, color=tab10[0])\n",
    "\t\t\tax.set_xlabel('JCC prediction score', fontsize=16)\n",
    "\t\t\tax.set_ylabel('Number of junctions', fontsize=16)\n",
    "\t\t\tax.set_yscale('log')\n",
    "\t\t\tax.tick_params(labelsize=16)\n",
    "\t\t\tax.set_title(f'{aligner.upper()} {gt_confidence.capitalize() if gt_confidence == \"illumina\" else gt_confidence}', fontsize=16)\n",
    "\t\t\tif gt_confidence == 'unfiltered':\n",
    "\t\t\t\tax.legend(fontsize=16) #only show legend for the last plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_6.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee3be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR J26675-L1_S1: 69359/69726 (99.47%) consensus donor, 69356/69726 (99.47%) consensus acceptor\n"
     ]
    }
   ],
   "source": [
    "#Supplementary Figure S7: splice motifs, canonical motif (GT/AG) strongly increases confidence. done running\n",
    "# Plot donor + acceptor motifs\n",
    "def plot_bar_motifs(data, file_dir):\n",
    "\tdonor_counts = data['donor_motif'].value_counts()\n",
    "\tacceptor_counts = data['acceptor_motif'].value_counts()\n",
    "\tfig, axes = plt.subplots(1, 2, figsize=(9, 4), squeeze=False)\n",
    "\tax = axes.flatten()[0]\n",
    "\tax.bar(donor_counts.index, donor_counts.values)\n",
    "\tax.set_xlabel('Motif')\n",
    "\tax.set_ylabel('Count')\n",
    "\tax.set_title('Donor Motifs')\n",
    "\tax.tick_params(axis='x', rotation=45)\n",
    "\tax = axes.flatten()[1]\n",
    "\tax.bar(acceptor_counts.index, acceptor_counts.values)\n",
    "\tax.set_xlabel('Motif')\n",
    "\tax.set_title('Acceptor Motifs')\n",
    "\tax.tick_params(axis='x', rotation=45)\n",
    "\tplt.savefig(file_dir, dpi=600, bbox_inches='tight')\n",
    "\tplt.close()\n",
    "\n",
    "\n",
    "# Function to get reverse complement\n",
    "def reverse_complement(seq):\n",
    "\tcomplement = str.maketrans('ATCGatcg', 'TAGCtagc')\n",
    "\treturn seq.translate(complement)[::-1]\n",
    "\n",
    "\n",
    "# Extract motifs at junctions\n",
    "def extract_junction_motifs(df, genome):\n",
    "\tdonor_seqs = []\n",
    "\tacceptor_seqs = []\n",
    "\tfor _, row in df.iterrows():\n",
    "\t\tchrom_seq = genome[row['chr']]\n",
    "\t\tstart = row['start']\n",
    "\t\tend = row['end']\n",
    "\t\tstrand = row['strand']\n",
    "\n",
    "\t\tdonor_seq = chrom_seq[start-1:start+1]\n",
    "\t\tacceptor_seq = chrom_seq[end-2:end]\n",
    "\n",
    "\t\tif strand == '-':\n",
    "\t\t\tacceptor_seq_ = reverse_complement(donor_seq)\n",
    "\t\t\tdonor_seq = reverse_complement(acceptor_seq)\n",
    "\t\t\tacceptor_seq = acceptor_seq_\n",
    "\t\tdonor_seqs.append(donor_seq)\n",
    "\t\tacceptor_seqs.append(acceptor_seq)\n",
    "\n",
    "\treturn pd.DataFrame({\n",
    "        'donor_motif': donor_seqs,\n",
    "        'acceptor_motif': acceptor_seqs\n",
    "    }, index=df.index)\n",
    "\n",
    "\n",
    "def extract_gene_id(attribute_str):\n",
    "\tpattern = r'gene_id \"([^\"]+)\"'\n",
    "\tmatch = re.search(pattern, attribute_str)\n",
    "\tif match:\n",
    "\t\tgene_id = match.group(1)\n",
    "\t\tgene = gene_id.split('.')[0]\n",
    "\t\treturn gene\n",
    "\telse:\n",
    "\t\treturn None\n",
    "\n",
    "\n",
    "if not os.path.exists(f'{data_dir}/Homo_sapiens.GRCh38.dna.primary_assembly.fa'):\n",
    "\tprint('Downloading Homo_sapiens.GRCh38.dna.primary_assembly.fa ...')\n",
    "\t!wget https://ftp.ensembl.org/pub/release-104/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n",
    "\t!gunzip Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n",
    "genome = Fasta(f'{data_dir}/Homo_sapiens.GRCh38.dna.primary_assembly.fa', as_raw=True)\n",
    "\n",
    "for aligner in ['star']:\n",
    "\tperc_consensus_donor = 0\n",
    "\tperc_consensus_acceptor = 0\n",
    "\tall_nr_sj = 0\n",
    "\tall_htf_dfs = pd.read_pickle(f\"{stats_dir}/scenario_3_hypothetical/tool_sjs_50_{aligner}_vs_GT_{aligner}_unfiltered.pkl\")['spliceai']\n",
    "\tfor (_, sample, _),htf_df in all_htf_dfs.items():\n",
    "\t\tif sample == 'J26675-L1_S1':\n",
    "\t\t\tlen_bef = len(htf_df)\n",
    "\t\t\thtf_df['start'] = htf_df.start+2\n",
    "\t\t\thtf_df = htf_df[['start', 'end', 'strand', 'chr']]\n",
    "\t\t\thtf_df.loc[:,['donor_motif','acceptor_motif']] = extract_junction_motifs(htf_df, genome)\n",
    "\t\t\tnr_consensus_donor = len(htf_df[htf_df['donor_motif'].isin(['GT','CT'])])\n",
    "\t\t\tnr_consensus_acceptor = len(htf_df[htf_df['acceptor_motif'].isin(['AG','AC'])])\n",
    "\t\t\tnr_sj = len(htf_df)\n",
    "\t\t\tall_nr_sj += nr_sj\n",
    "\t\t\tperc_consensus_acceptor += nr_consensus_acceptor\n",
    "\t\t\tperc_consensus_donor += nr_consensus_donor\n",
    "\t\t\tplot_bar_motifs(htf_df, f'{plt_dir}/supplementary_figure_7.tif')\n",
    "\t\t\tprint(f'{aligner.upper()} {sample}: {nr_consensus_donor}/{nr_sj} ({np.round((nr_consensus_donor/nr_sj)*100,2)}%) consensus donor motif, {nr_consensus_acceptor}/{nr_sj} ({np.round((nr_consensus_acceptor/nr_sj)*100,2)}%) consensus acceptor motif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed80572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S8\n",
    "# Distribution of prediction scores of JCC on gold standard data STAR unfiltered, STAR Illumina filtered, STAR cutoff filtered, HISAT2 unfiltered. \n",
    "# The score distribution of splice junctions that were not found in the filtered down 50M reads data (shown in blue) is compared to the score distribution of splice junctions that were not annotated in the reference genome (shown in orange). \n",
    "# In panel a. the prediction score distribution is visualized for Scenario 2: “Predicting junctions that could be detected with higher sequencing depth” Real-world setting, in panel b. \n",
    "# for Scenario 2: “Predicting junctions that could be detected with higher sequencing depth” Hypothetical setting. \n",
    "# This is shown on sample J26675-L1_S1 subsample 0 as an example, but is similar for the other three samples and their subsamples.\n",
    "tool = 'jcc'\n",
    "sample = 'J26675-L1_S1'\n",
    "run = 0\n",
    "aligner = 'star'\n",
    "tab10 = plt.cm.tab10.colors\n",
    "fig, axes = plt.subplots(3, 4, figsize=(19, 11))  # 4x3 subplots\n",
    "# read in sj in 50M input\n",
    "sj_50 = pd.read_csv(f\"{data_dir}/50M/star/{sample}_50M_{run}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "# read in reference genome sj\n",
    "reference_sj = pd.read_csv(f\"{data_dir}/annotated.sj\",sep='\\t', header=None, names=[\"chr\", \"start\", \"end\", \"strand\"], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int})\n",
    "for i, filter_type in enumerate([\"unfiltered\",\"illumina\",\"cutoff\"]):\n",
    "\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type \n",
    "\tfile_sj = f'{stats_dir}/scenario_2_real_world/tool_sjs_50_{aligner}_vs_GT_{aligner}_{filter_type}.pkl'\n",
    "\twith open(file_sj, 'rb') as f:\n",
    "\t\ttool_sjs = pd.read_pickle(f)\n",
    "\tfor ann, sj in tool_sjs[tool].items():\n",
    "\t\t_, sample_id, run_id = ann\n",
    "\t\trun_id = int(run_id)\n",
    "\t\tif run_id == run and sample_id == sample:\n",
    "\t\t\t# plot score distribution of sj that are in groundtruth - that are not in 50m data vs not in reference genome\n",
    "\t\t\tsj_not_in_50 = sj.merge(sj_50, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\tsj_not_in_50 = sj_not_in_50[sj_not_in_50['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\tsj_not_in_reference = sj.merge(reference_sj, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\tsj_not_in_reference = sj_not_in_reference[sj_not_in_reference['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\tbins = np.linspace(0, 1, 50)\n",
    "\t\t\tax = axes[0, i]\n",
    "\t\t\tax.hist(sj_not_in_reference['pred'], bins=bins, label='not in reference genome', alpha=0.5, color=tab10[2])\n",
    "\t\t\tax.hist(sj_not_in_50['pred'], bins=bins, label='not in 50M input data', alpha=0.5, color=tab10[0])\n",
    "\t\t\tax.set_xlabel('Prediction score', fontsize=16)\n",
    "\t\t\tax.set_ylabel('Number of junctions', fontsize=16)\n",
    "\t\t\tax.set_yscale('log')\n",
    "\t\t\tax.tick_params(labelsize=16)\n",
    "\t\t\tax.set_title(f'{aligner.upper()}{'2' if aligner=='hisat' else ''} {filter_type_}', fontsize=18)\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tax.text(-0.25, 1.2, 'a.', transform=ax.transAxes, fontsize=22, va='top', ha='right', weight='bold')\n",
    "\t\t\t\tax.text(-0.25, 0.5, tool.upper(), transform=ax.transAxes, fontsize=20, va='center', ha='right', rotation=90)\n",
    "axes[0,3].axis('off')\n",
    "for i, (aligner, filter_type) in enumerate([(\"star\", \"unfiltered\"), (\"star\", \"illumina\"), (\"star\", \"cutoff\"), (\"hisat\", \"unfiltered\")]):\n",
    "\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type \n",
    "\tfile_sj = f'{stats_dir}/scenario_2_hypothetical/tool_sjs_50_{aligner}_vs_GT_{aligner}_{filter_type}.pkl'\n",
    "\twith open(file_sj, 'rb') as f:\n",
    "\t\ttool_sjs = pd.read_pickle(f)\n",
    "\tfor i_y, tool in enumerate(['deepsplice','spliceai']):\n",
    "\t\ti_y += 1\n",
    "\t\tfor ann, sj in tool_sjs[tool].items():\n",
    "\t\t\t_, sample_id, run_id = ann\n",
    "\t\t\tif sample_id == sample:\n",
    "\t\t\t\tax = axes[i_y, i]\n",
    "\t\t\t\t# plot score distribution of sj that are in groundtruth - that are not in 50m data vs not in reference genome\n",
    "\t\t\t\tsj_not_in_50 = sj.merge(sj_50, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\t\tsj_not_in_50 = sj_not_in_50[sj_not_in_50['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\t\tsj_not_in_reference = sj.merge(reference_sj, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\t\tsj_not_in_reference = sj_not_in_reference[sj_not_in_reference['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\t\tbins = np.linspace(0, 1 if tool=='spliceai' else 1.7, 50)\n",
    "\t\t\t\tax.hist(sj_not_in_reference['pred'], bins=bins, label='not in reference genome', alpha=0.5, color=tab10[2])\n",
    "\t\t\t\tax.hist(sj_not_in_50['pred'], bins=bins, label='not in 50M input data', alpha=0.5, color=tab10[0])\n",
    "\t\t\t\tax.set_xlabel('Prediction score', fontsize=16)\n",
    "\t\t\t\tax.set_ylabel('Number of junctions', fontsize=16)\n",
    "\t\t\t\tax.set_yscale('log')\n",
    "\t\t\t\tax.tick_params(labelsize=16)\n",
    "\t\t\t\tax.set_title(f'{aligner.upper()}{'2' if aligner=='hisat' else ''} {filter_type_}', fontsize=18)\n",
    "\t\t\t\tif (filter_type == 'unfiltered') & (tool == 'spliceai') & (aligner == 'hisat'):\n",
    "\t\t\t\t\tax.legend(fontsize=16)\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\ttool_ = 'DeepSplice' if tool == 'deepsplice' else 'SpliceAI'\n",
    "\t\t\t\t\tif i_y == 1: ax.text(-0.25, 1.2, 'b.', transform=ax.transAxes, fontsize=22, va='top', ha='right', weight='bold')\n",
    "\t\t\t\t\tax.text(-0.25, 0.5, tool_, transform=ax.transAxes, fontsize=20, va='center', ha='right', rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_8.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb415c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.41% of splice junctions from J26675-L1_S1 are found in both aligners 500M data.\n",
      "96.79% of splice junctions from J26676-L1_S2 are found in both aligners 500M data.\n",
      "97.16% of splice junctions from J26677-L1_S3 are found in both aligners 500M data.\n",
      "97.7% of splice junctions from J26678-L1_S4 are found in both aligners 500M data.\n"
     ]
    }
   ],
   "source": [
    "# Supplementary Figure S9: Overlap of splice junctions aligned with HISAT vs STAR for all samples.\n",
    "fig, axes = plt.subplots(2, 2, figsize=(2*5, 2*4.5), squeeze=False)\n",
    "for i, sample in enumerate(['J26675-L1_S1','J26676-L1_S2','J26677-L1_S3','J26678-L1_S4']):\n",
    "\tax = axes.flatten()[i]\n",
    "\tdf_hisat = pd.read_csv(f'{data_dir}/500M/{sample}_hisat_unfiltered.sj',usecols=[0,1,2,3],names=['chr','start','end','strand'],delimiter='\\t',dtype={'chr':str})\n",
    "\tdf_star = pd.read_csv(f'{data_dir}/500M/{sample}_star_unfiltered.sj',usecols=[0,1,2,3],names=['chr','start','end','strand'],delimiter='\\t',dtype={'chr':str})\n",
    "\tdf_both = df_hisat.merge(df_star, on=['start', 'end', 'strand', 'chr'],how='inner')\n",
    "\tprint(f'{round((len(df_both)/len(df_hisat))*100,2)}% of splice junctions from {sample} are found in both aligners 500M data.')\n",
    "\n",
    "\t# Sets of junctions\n",
    "\tset_hisat = set(zip(df_hisat['chr'], df_hisat['start'], df_hisat['end'], df_hisat['strand']))\n",
    "\tset_star = set(zip(df_star['chr'], df_star['start'], df_star['end'], df_star['strand']))\n",
    "\tonly_hisat = len(set_hisat - set_star)\n",
    "\tonly_star = len(set_star - set_hisat)\n",
    "\tboth = len(set_hisat & set_star)\n",
    "\tax.set_title(f'Sample {sample}', fontweight='bold')\n",
    "\tvenn2(subsets = (len(set_hisat - set_star), len(set_star - set_hisat), len(set_hisat & set_star)),\n",
    "\t\tset_labels = ('HISAT2 500M unfiltered', 'STAR 500M unfiltered'),ax=ax)\n",
    "plt.savefig(f'{plt_dir}/supplementary_figure_9.tif', dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S10: Calibration curves of the tools over the different evaluation scenarios for STAR unfiltered, STAR Illumina filtered, STAR cutoff filtered and HISAT unfiltered gold standards.\n",
    "TOOL_COLORS = {'deepsplice':0, 'spliceai':1, 'jcc':2, 'baseline':3, 'alphagenome':4}\n",
    "tool2tool = {'alphagenome':'AlphaGenome','spliceai':'SpliceAI','deepsplice':'DeepSplice','jcc':'JCC'}\n",
    "fig, axes = plt.subplots(5, 4, figsize=(4*4, 5*3.5), squeeze=False)\n",
    "for row_idx, scenario in enumerate(['scenario_1a','scenario_1b','scenario_2_hypothetical','scenario_2_real_world','scenario_3_hypothetical']): \n",
    "\tfor col_idx, (aligner, gt_confidence) in enumerate([('star','unfiltered'),('star','illumina'),('star','cutoff'),('hisat','unfiltered')]):\n",
    "\t\tax = axes[row_idx][col_idx]\n",
    "\t\tif (('real_world' in scenario) and (aligner == 'hisat')):\n",
    "\t\t\tax.axis('off')\n",
    "\t\telse:\n",
    "\t\t\tsj_file = f'{stats_dir}/{scenario}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\t\t\tsj_file_ag = f'{stats_dir_ag}/{scenario}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\t\t\tif (scenario == 'scenario_3_hypothetical') and include_ag_results and os.path.exists(sj_file_ag):\n",
    "\t\t\t\tsj_file = sj_file_ag\n",
    "\t\t\twith open(sj_file,'rb') as f:\n",
    "\t\t\t\ttool_sjs_50 = pickle.load(f)\n",
    "\t\t\t\n",
    "\t\t\tn_bins=10\n",
    "\t\t\tbin_preds = []\n",
    "\t\t\tbin_trues = []\n",
    "\t\t\tfor tool, sjs in tool_sjs_50.items():\n",
    "\t\t\t# Gather all predictions/labels for scenario\n",
    "\t\t\t\ty_true = np.concatenate([sj[\"label\"] for sj in sjs.values()])\n",
    "\t\t\t\ty_pred = np.concatenate([sj[\"pred\"] for sj in sjs.values()])\n",
    "\n",
    "\t\t\t\tbins = np.linspace(0, 1, n_bins+1)\n",
    "\t\t\t\tbinids = np.digitize(y_pred, bins) - 1 # binids from 0 to n_bins-1\n",
    "\t\t\t\t\n",
    "\t\t\t\tbin_true = []\n",
    "\t\t\t\tbin_pred = []\n",
    "\t\t\t\tbin_count = []\n",
    "\t\t\t\tfor i in range(n_bins):\n",
    "\t\t\t\t\tmask = (binids == i)\n",
    "\t\t\t\t\tif np.any(mask):\n",
    "\t\t\t\t\t\tbin_true.append(np.mean(y_true[mask]))\n",
    "\t\t\t\t\t\tbin_pred.append(np.mean(y_pred[mask]))\n",
    "\t\t\t\t\t\tbin_count.append(np.sum(mask))\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tbin_true.append(np.nan)\n",
    "\t\t\t\t\t\tbin_pred.append((bins[i] + bins[i+1]) / 2)\n",
    "\t\t\t\t\t\tbin_count.append(0)\n",
    "\t\t\t\tbin_trues.append(bin_true)\n",
    "\t\t\t\tbin_preds.append(bin_pred)\n",
    "\n",
    "\t\t\tmask = (~np.isnan(bin_true))\n",
    "\t\t\tfor (tool, bin_pred, bin_true) in zip(tool_sjs_50.keys(),bin_preds,bin_trues):\n",
    "\t\t\t\tax.plot(bin_pred, bin_true, \"s-\", label=f\"{tool2tool[tool]} Calibration\", zorder=2, color=plt.get_cmap('tab10')(TOOL_COLORS[tool]))\n",
    "\t\t\t\tax.fill_between(bin_pred, 0, bin_true, alpha=0.1, color=plt.get_cmap('tab10')(TOOL_COLORS[tool]))\n",
    "\t\t\tax.plot([0,1],[0,1], \"--k\", label=\"Perfect Calibration\", zorder=1)\n",
    "\t\t\tax.set_xlabel(\"Mean predicted probability\")\n",
    "\t\t\tax.set_ylabel(\"Empirical frequency (Fraction of positives)\")\n",
    "\t\t\tax.set_xlim(0,1)\n",
    "\t\t\tax.set_ylim(0,1)\n",
    "\t\t\tif row_idx == 0:\n",
    "\t\t\t\tax.set_title(f\"{aligner.upper()}{'2' if aligner=='hisat' else ''} {gt_confidence}\",fontweight='bold', fontsize=12)\n",
    "\t\t\tif col_idx == 0:\n",
    "\t\t\t\tscenario_name = scenario.capitalize().replace('_', ' ')\n",
    "\t\t\t\tax.text(-0.25, 0.5, scenario_name, transform=ax.transAxes, fontsize=12, fontweight='bold', va='center', rotation=90)\n",
    "\t\t\tax.legend()\n",
    "\t\t\tax.grid(True, zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_10.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84689f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure S11: Distribution of the prediction scores of the three different tools DeepSplice, SpliceAI, and JCC, after running on the 500M reads RNA-seq data aligned with STAR. This is shown for sample J26675-L1_S1 as an example, but is similar for the other three samples.\n",
    "ds_pred = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/deepsplice_pred.csv',low_memory=False)\n",
    "sa_pred = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/spliceai_pred.csv',low_memory=False)\n",
    "jcc_pred = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/jcc_pred.csv',low_memory=False)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.hist(ds_pred['pred'], bins=50, label='DeepSplice', alpha=0.5)\n",
    "plt.hist(sa_pred['pred'], bins=50, label='SpliceAI', alpha=0.5)\n",
    "plt.hist(jcc_pred['pred'], bins=50, label='JCC', alpha=0.5)\n",
    "plt.xlabel('Prediction score', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Number of junctions', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_11.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
