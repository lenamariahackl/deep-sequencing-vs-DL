{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04f610a",
   "metadata": {},
   "source": [
    "For producing the figures you will need the plotting conda environment:\n",
    "\n",
    "conda env create -f eval.yml\n",
    "\n",
    "And you will need to first run:\n",
    "\n",
    "python evaluation_scenarios.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f253b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "main_dir = \".\" # TODO set working directory\n",
    "data_dir = f\"{main_dir}/data\"\n",
    "pred_dir = f'{data_dir}/predictions'\n",
    "out_dir = f\"{main_dir}/out\"\n",
    "stats_dir = f\"{out_dir}/stats\"\n",
    "plt_dir = f\"{out_dir}/plots\"\n",
    "os.makedirs(plt_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Distribution of JCC prediction scores for Scenario 3 “Predicting hard-to-find junctions” in Real-world use case\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "in_dir = f'{stats_dir}/scenario_3_real_world'\n",
    "aligner=\"star\"\n",
    "tool = \"jcc\"\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 4))  # 3 horizontal subplots\n",
    "for i, gt_confidence in enumerate([\"unfiltered\",\"illumina\",\"cutoff\"]):\n",
    "\tfile_sj_50 = f'{in_dir}/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\tgt_confidence = gt_confidence.capitalize() if gt_confidence == 'illumina' else gt_confidence\n",
    "\twith open(file_sj_50, 'rb') as f:\n",
    "\t\tsjs_50 = pd.read_pickle(f)\n",
    "\t\tfor ann, sj in sjs_50[tool].items():\n",
    "\t\t\t_, sample_id, run_id = ann\n",
    "\t\t\tif sample_id == 'J26675-L1_S1' and run_id == '0':\n",
    "\t\t\t\t\tax = axs[i]\n",
    "\t\t\t\t\tbins = np.histogram_bin_edges(sj['pred'], bins=25)\n",
    "\t\t\t\t\tax.hist(sj[sj['label'] == 0]['pred'], bins=bins, alpha=0.6, label='Negative (label=0)')\n",
    "\t\t\t\t\tax.hist(sj[sj['label'] == 1]['pred'], bins=bins, alpha=0.6, label='Positive (label=1)')\n",
    "\t\t\t\t\tax.set_xlabel(f'{tool.upper()} prediction score', fontsize=16)\n",
    "\t\t\t\t\tax.set_ylabel('Number of junctions', fontsize=16)\n",
    "\t\t\t\t\tax.set_yscale('log')\n",
    "\t\t\t\t\tax.tick_params(labelsize=16)\n",
    "\t\t\t\t\tax.set_xlim(-0.02, 1.02)\n",
    "\t\t\t\t\tif i == 2:\n",
    "\t\t\t\t\t\tax.legend(fontsize=16)\n",
    "\t\t\t\t\tax.grid(True)\n",
    "\t\t\t\t\tax.title.set_text(f'{aligner.upper()} {gt_confidence}')\n",
    "\t\t\t\t\tax.title.set_fontsize(18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plt_dir}/figure_2.tif', dpi=600)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure 1: plot upsetplot of all groundtruths \n",
    "from upsetplot import UpSet\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [\"GRCh38.106 reference genome\"]\n",
    "reference_sj = pd.read_csv(f\"{data_dir}/annotated.sj\",sep='\\t', header=None, names=[\"chr\", \"start\", \"end\", \"strand\"], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int})\n",
    "# keep only chr1-22, X, Y\n",
    "reference_sj = reference_sj[reference_sj[\"chr\"].isin([str(i) for i in range(1,23)] + [\"X\",\"Y\"])]\n",
    "reference_sj = reference_sj.drop_duplicates()\n",
    "\n",
    "sets = [reference_sj]\n",
    "\n",
    "for aligner in [\"hisat\",\"star\"]:\n",
    "\tfor filter_type in ([\"unfiltered\",\"illumina\",\"cutoff\"] if aligner == \"star\" else [\"unfiltered\"]):\n",
    "\t\tsample_sets = []\n",
    "\t\tfor sample in [\"J26675-L1_S1\",\"J26676-L1_S2\",\"J26677-L1_S3\",\"J26678-L1_S4\"]:\n",
    "\t\t\tsample_sets.append(pd.read_csv(f\"{data_dir}/500M/{sample}_{aligner}_{filter_type}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"]))\n",
    "\t\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type\n",
    "\t\tfilter_type_ = filter_type_ if filter_type_ == \"unfiltered\" else filter_type_+\" filtered\"\n",
    "\t\taligner_ = aligner.upper()+'2' if aligner == \"hisat\" else aligner.upper()\n",
    "\t\tlabels.append(aligner_+\" \"+filter_type_+\" gold standard\")\n",
    "\t\tcombined_sj = pd.concat(sample_sets, ignore_index=True).drop_duplicates()\n",
    "\t\tsets.append(combined_sj)\n",
    "\n",
    "# Merge all dataframes with an additional 'source' column\n",
    "merged_df = pd.concat(\n",
    "\t[df.assign(source=name) for name, df in zip(labels, sets)],\n",
    "\tignore_index=True\n",
    ")\n",
    "\n",
    "# get counts for each group\n",
    "binary_merged = merged_df.pivot_table(index=['chr','start','end','strand'], columns='source', aggfunc='size', fill_value=0).clip(upper=1)\n",
    "g = binary_merged.groupby(binary_merged.columns.tolist()).size()\n",
    "g = g.reorder_levels(labels)\n",
    "\n",
    "upset = UpSet(g, show_counts=True, sort_categories_by='-input', sort_by='-degree')\n",
    "upset.plot()\n",
    "plt.subplots_adjust(right=1.25)\n",
    "out_file = os.path.join(plt_dir, f\"supplementary_figure_1.tif\")\n",
    "plt.savefig(out_file, dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6712d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3\n",
    "# plot venn diagram for three sets a,b,c\n",
    "def prep_for_venn3(a, b, c, colored = True):\n",
    "\tthree_sets = {}\n",
    "\ta_c = a.merge(c, how='inner', on=['chr','start','end','strand'])\n",
    "\ta_b_c = a_c.merge(b, how='outer', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['101'] = len(a_b_c[a_b_c._merge=='left_only'])\n",
    "\tthree_sets['111'] = len(a_b_c[a_b_c._merge=='both'])\n",
    "\tb_c = b.merge(c, how='inner', on=['chr','start','end','strand'])\n",
    "\ta_b_c = b_c.merge(a, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['011'] = len(a_b_c[a_b_c._merge=='left_only'])\n",
    "\ta_b = a.merge(b, how='inner', on=['chr','start','end','strand'])\n",
    "\ta_b_c = a_b.merge(c, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['110'] = len(a_b_c[a_b_c._merge=='left_only'])\n",
    "\ta_nb = a.merge(b, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\ta_nb_nc = a_nb[a_nb._merge=='left_only'].drop(columns=['_merge']).merge(c, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['100'] = len(a_nb_nc[a_nb_nc._merge=='left_only'])\n",
    "\tna_b = a.merge(b, how='right', on=['chr','start','end','strand'], indicator=True)\n",
    "\tna_b_nc = na_b[na_b._merge=='right_only'].drop(columns=['_merge']).merge(c, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['010'] = len(na_b_nc[na_b_nc._merge=='left_only'])\n",
    "\tna_c = a.merge(c, how='right', on=['chr','start','end','strand'], indicator=True)\n",
    "\tna_nb_c = na_c[na_c._merge=='right_only'].drop(columns=['_merge']).merge(b, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\tthree_sets['001'] = len(na_nb_c[na_nb_c._merge=='left_only'])\n",
    "\ttab10 = plt.cm.tab10.colors \n",
    "\tcolors = [tab10[0], tab10[1], tab10[2]] if colored else [tab10[0], tab10[0], tab10[0]]\n",
    "\treturn three_sets, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure 2\n",
    "import pandas as pd\n",
    "\n",
    "# plot overlap STAR 500M with different filtering in VENN diagrams with 3 sets as example sample_id J26675-L1_S1\n",
    "sample = 'J26675-L1_S1'\n",
    "aligner = 'star'\n",
    "sjs = {}\n",
    "for filter_type in [\"unfiltered\",\"illumina\",\"cutoff\"]:\n",
    "\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type\n",
    "\tsjs[f'{aligner.upper()} {filter_type_}'] = pd.read_csv(f\"{data_dir}/500M/{sample}_{aligner}_{filter_type}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "out_file = f'{plt_dir}/supplementary_figure_2.tif'\n",
    "three_sets, colors = prep_for_venn3(*sjs.values(), colored=False)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "venn3(subsets=three_sets, set_labels = sjs.keys(), set_colors=colors, ax=ax)\n",
    "plt.savefig(out_file, dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure 3\n",
    "import pandas as pd\n",
    "\t\t\n",
    "# plot overlap 50M with 500M with reference genome gtf in VENN diagrams with 3 sets as example subsample 0 of sample_id J26675-L1_S1\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "for ax, aligner in zip(axes,[\"star\",\"hisat\"]):\n",
    "\tsample = 'J26675-L1_S1'\n",
    "\ti=0\n",
    "\tfilter_type = 'unfiltered'\n",
    "\ttitle =''\n",
    "\tfull = pd.read_csv(f\"{data_dir}/500M/{sample}_{aligner}_{filter_type}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "\tsubsampled = pd.read_csv(f\"{data_dir}/50M/{aligner}/{sample}_50M_{i}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "\treference_sj = pd.read_csv(f\"{data_dir}/annotated.sj\",sep='\\t', header=None, names=[\"chr\", \"start\", \"end\", \"strand\"], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int})\n",
    "\taligner_ = aligner.upper()+'2' if aligner == \"hisat\" else aligner.upper()\n",
    "\tthree_sets, colors = prep_for_venn3(full, subsampled, reference_sj)\n",
    "\tvenn = venn3(subsets=three_sets, set_labels = [f'{aligner_} 500M', f'{aligner_} 50M', 'reference genome'], set_colors=colors, ax=ax)\n",
    "\t# make set labels colored\n",
    "\tfor i, text in enumerate(venn.set_labels):\n",
    "\t\ttext.set_color(plt.cm.tab10.colors [i])\n",
    "out_file = f'{plt_dir}/supplementary_figure_3.tif'\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_file, dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure 4\n",
    "# JCC scenario_2_real_world positives plot distribution score in 50m data vs not in 50m data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "tab10 = plt.cm.tab10.colors \n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))  # 3 horizontal subplots\n",
    "for i, gt_confidence in enumerate([\"unfiltered\",\"illumina\",\"cutoff\"]):\n",
    "\tax = axes[i]\n",
    "\taligner =\"star\"\n",
    "\tfile_sj_50 = f'{stats_dir}/scenario_2_real_world/tool_sjs_50_{aligner}_vs_GT_{aligner}_{gt_confidence}.pkl'\n",
    "\twith open(file_sj_50, 'rb') as f:\n",
    "\t\ttool_sjs_50 = pd.read_pickle(f)\n",
    "\ttool ='jcc'\n",
    "\tfor ann_50, sj_50 in tool_sjs_50[tool].items():\n",
    "\t\t_, sample_id, run_id = ann_50\n",
    "\t\trun_id = int(run_id)\n",
    "\t\tif run_id == 0 and sample_id == \"J26675-L1_S1\":\n",
    "\t\t\tpositives = sj_50[sj_50.label == 1] # positives\n",
    "\t\t\t# read in sj in 50M input\n",
    "\t\t\tinput_data = pd.read_csv(f\"{data_dir}/50M/{aligner}/{sample_id}_50M_{run_id}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "\t\t\t# add column in_input 1 or 0\n",
    "\t\t\tpositives = positives.merge(input_data, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\tpositives['_merge'] = positives['_merge'].astype('object').replace({'both': 1, 'left_only': 0, 'right_only': 0}).astype(int)\n",
    "\t\t\tpositives.rename(columns={'_merge': 'in_input'},inplace=True, errors='raise')\n",
    "\t\t\t# plot distribution of jcc score of sj that are in groundtruth - that are in in 50m data vs not in 50m data\n",
    "\t\t\tax.hist(positives[positives.in_input == 1]['pred'], bins=50, label='in 50M input data', alpha=0.5, color=tab10[1])\n",
    "\t\t\tax.hist(positives[positives.in_input == 0]['pred'], bins=50, label='not in 50M input data', alpha=0.5, color=tab10[0])\n",
    "\t\t\tax.set_xlabel('JCC prediction score', fontsize=16)\n",
    "\t\t\tax.set_ylabel('Number of junctions', fontsize=16)\n",
    "\t\t\tax.set_yscale('log')\n",
    "\t\t\tax.tick_params(labelsize=16)\n",
    "\t\t\tax.set_title(f'{aligner.upper()} {gt_confidence.capitalize() if gt_confidence == \"illumina\" else gt_confidence}', fontsize=16)\n",
    "\t\t\tif gt_confidence == 'unfiltered':\n",
    "\t\t\t\tax.legend(fontsize=16) #only show legend for the last plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_4.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed80572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure 5\n",
    "# Distribution of prediction scores of JCC on gold standard data STAR unfiltered, STAR Illumina filtered, STAR cutoff filtered, HISAT2 unfiltered. \n",
    "# The score distribution of splice junctions that were not found in the filtered down 50M reads data (shown in blue) is compared to the score distribution of splice junctions that were not annotated in the reference genome (shown in orange). \n",
    "# In panel a. the prediction score distribution is visualized for Scenario 2: “Predicting junctions that could be detected with higher sequencing depth” Real-world setting, in panel b. \n",
    "# for Scenario 2: “Predicting junctions that could be detected with higher sequencing depth” Hypothetical setting. \n",
    "# This is shown on sample J26675-L1_S1 subsample 0 as an example, but is similar for the other three samples and their subsamples.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tool = 'jcc'\n",
    "sample = 'J26675-L1_S1'\n",
    "run = 0\n",
    "aligner = 'star'\n",
    "tab10 = plt.cm.tab10.colors\n",
    "fig, axes = plt.subplots(3, 4, figsize=(19, 11))  # 4x3 subplots\n",
    "# read in sj in 50M input\n",
    "sj_50 = pd.read_csv(f\"{data_dir}/50M/star/{sample}_50M_{run}.sj\", usecols=[0,1,2,3], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int}, sep=\"\\t\", header=None, names=[\"chr\",\"start\",\"end\",\"strand\"])\n",
    "# read in reference genome sj\n",
    "reference_sj = pd.read_csv(f\"{data_dir}/annotated.sj\",sep='\\t', header=None, names=[\"chr\", \"start\", \"end\", \"strand\"], dtype={\"chr\": str, \"start\": int, \"end\": int, \"strand\": int})\n",
    "for i, filter_type in enumerate([\"unfiltered\",\"illumina\",\"cutoff\"]):\n",
    "\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type \n",
    "\tfile_sj = f'{stats_dir}/scenario_2_real_world/tool_sjs_50_{aligner}_vs_GT_{aligner}_{filter_type}.pkl'\n",
    "\twith open(file_sj, 'rb') as f:\n",
    "\t\ttool_sjs = pd.read_pickle(f)\n",
    "\tfor ann, sj in tool_sjs[tool].items():\n",
    "\t\t_, sample_id, run_id = ann\n",
    "\t\trun_id = int(run_id)\n",
    "\t\tif run_id == run and sample_id == sample:\n",
    "\t\t\t# plot score distribution of sj that are in groundtruth - that are not in 50m data vs not in reference genome\n",
    "\t\t\tsj_not_in_50 = sj.merge(sj_50, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\tsj_not_in_50 = sj_not_in_50[sj_not_in_50['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\tsj_not_in_reference = sj.merge(reference_sj, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\tsj_not_in_reference = sj_not_in_reference[sj_not_in_reference['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\tbins = np.linspace(0, 1, 50)\n",
    "\t\t\tax = axes[0, i]\n",
    "\t\t\tax.hist(sj_not_in_reference['pred'], bins=bins, label='not in reference genome', alpha=0.5, color=tab10[2])\n",
    "\t\t\tax.hist(sj_not_in_50['pred'], bins=bins, label='not in 50M input data', alpha=0.5, color=tab10[0])\n",
    "\t\t\tax.set_xlabel('Prediction score', fontsize=16)\n",
    "\t\t\tax.set_ylabel('Number of junctions', fontsize=16)\n",
    "\t\t\tax.set_yscale('log')\n",
    "\t\t\tax.tick_params(labelsize=16)\n",
    "\t\t\tax.set_title(f'{aligner.upper()} {filter_type_}', fontsize=18)\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tax.text(-0.25, 1.2, 'a.', transform=ax.transAxes, fontsize=22, va='top', ha='right', weight='bold')\n",
    "\t\t\t\tax.text(-0.25, 0.5, tool.upper(), transform=ax.transAxes, fontsize=20, va='center', ha='right', rotation=90)\n",
    "axes[0,3].axis('off')\n",
    "for i, (aligner, filter_type) in enumerate([(\"star\", \"unfiltered\"), (\"star\", \"illumina\"), (\"star\", \"cutoff\"), (\"hisat\", \"unfiltered\")]):\n",
    "\tfilter_type_ = filter_type.capitalize() if filter_type == \"illumina\" else filter_type \n",
    "\tfile_sj = f'{stats_dir}/scenario_2_hypothetical/tool_sjs_50_{aligner}_vs_GT_{aligner}_{filter_type}.pkl'\n",
    "\twith open(file_sj, 'rb') as f:\n",
    "\t\ttool_sjs = pd.read_pickle(f)\n",
    "\tfor i_y, tool in enumerate(['deepsplice','spliceai']):\n",
    "\t\ti_y += 1\n",
    "\t\tfor ann, sj in tool_sjs[tool].items():\n",
    "\t\t\t_, sample_id, run_id = ann\n",
    "\t\t\tif sample_id == sample:\n",
    "\t\t\t\tax = axes[i_y, i]\n",
    "\t\t\t\t# plot score distribution of sj that are in groundtruth - that are not in 50m data vs not in reference genome\n",
    "\t\t\t\tsj_not_in_50 = sj.merge(sj_50, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\t\tsj_not_in_50 = sj_not_in_50[sj_not_in_50['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\t\tsj_not_in_reference = sj.merge(reference_sj, how='left', on=['chr','start','end','strand'], indicator=True)\n",
    "\t\t\t\tsj_not_in_reference = sj_not_in_reference[sj_not_in_reference['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\t\t\t\tbins = np.linspace(0, 1 if tool=='spliceai' else 1.7, 50)\n",
    "\t\t\t\tax.hist(sj_not_in_reference['pred'], bins=bins, label='not in reference genome', alpha=0.5, color=tab10[2])\n",
    "\t\t\t\tax.hist(sj_not_in_50['pred'], bins=bins, label='not in 50M input data', alpha=0.5, color=tab10[0])\n",
    "\t\t\t\tax.set_xlabel('Prediction score', fontsize=16)\n",
    "\t\t\t\tax.set_ylabel('Number of junctions', fontsize=16)\n",
    "\t\t\t\tax.set_yscale('log')\n",
    "\t\t\t\tax.tick_params(labelsize=16)\n",
    "\t\t\t\tax.set_title(f'{aligner.upper()} {filter_type_}', fontsize=18)\n",
    "\t\t\t\tif (filter_type == 'unfiltered') & (tool == 'spliceai') & (aligner == 'hisat'):\n",
    "\t\t\t\t\tax.legend(fontsize=16)\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\ttool_ = 'DeepSplice' if tool == 'deepsplice' else 'SpliceAI'\n",
    "\t\t\t\t\tif i_y == 1: ax.text(-0.25, 1.2, 'b.', transform=ax.transAxes, fontsize=22, va='top', ha='right', weight='bold')\n",
    "\t\t\t\t\tax.text(-0.25, 0.5, tool_, transform=ax.transAxes, fontsize=20, va='center', ha='right', rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_5.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28866440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure 6: Difference max and avg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "for tool in ['spliceai']:\n",
    "\tmaxi = pd.read_csv(f'{pred_dir}/annotated/{tool}_pred_max.csv',low_memory=False)\n",
    "\tavgi = pd.read_csv(f'{pred_dir}/annotated/{tool}_pred_avg.csv',low_memory=False)\n",
    "\tmaxi = maxi.merge(avgi, on=['chr','start','end','strand'],suffixes=('_max','_avg'))\n",
    "\tmaxi['pred_diff'] = maxi['pred_max'] - maxi['pred_avg']\n",
    "\tprint(f'for reference genome {len(maxi[maxi.pred_diff > 0.01])}/{len(maxi)} predictions differ more than 0.01 between max and avg for {tool}')\n",
    "for tool in ['spliceai','jcc']:\n",
    "\tmaxi = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/{tool}_pred_max.csv',low_memory=False)\n",
    "\tavgi = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/{tool}_pred_avg.csv',low_memory=False)\n",
    "\tmaxi = maxi.merge(avgi, on=['chr','start','end','strand'],suffixes=('_max','_avg'))\n",
    "\tmaxi['pred_diff'] = maxi['pred_max'] - maxi['pred_avg']\n",
    "\tprint(f'for 500M STAR J26675-L1_S1 {len(maxi[maxi.pred_diff > 0.01])}/{len(maxi)} predictions differ more than 0.01 between max and avg for {tool}')\n",
    "# for SpliceAI whether to take the max or the avg is not highly important, the difference is not that big, only for 1 case it is more than 0.01\n",
    "# for JCC the difference is more pronounced\n",
    "# plot distribution of the differences\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(maxi['pred_diff'], bins=100, alpha=0.5)\n",
    "plt.xlabel('Difference between maximum and mean combined JCC score', fontsize=16)\n",
    "plt.ylabel('Number of junctions', fontsize=16)\n",
    "plt.yscale('log')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_6.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84689f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Figure 7: Distribution of the prediction scores of the three different tools DeepSplice, SpliceAI, and JCC, after running on the 500M reads RNA-seq data aligned with STAR. This is shown for sample J26675-L1_S1 as an example, but is similar for the other three samples.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "ds_pred = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/deepsplice_pred.csv',low_memory=False)\n",
    "sa_pred = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/spliceai_pred_avg.csv',low_memory=False)\n",
    "jcc_pred = pd.read_csv(f'{pred_dir}/500M/J26675-L1_S1/star/jcc_pred_avg.csv',low_memory=False)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.hist(ds_pred['pred'], bins=50, label='DeepSplice', alpha=0.5)\n",
    "plt.hist(sa_pred['pred'], bins=50, label='SpliceAI', alpha=0.5)\n",
    "plt.hist(jcc_pred['pred'], bins=50, label='JCC', alpha=0.5)\n",
    "plt.xlabel('Prediction score', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Number of junctions', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.savefig(f\"{plt_dir}/supplementary_figure_7.tif\", dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
